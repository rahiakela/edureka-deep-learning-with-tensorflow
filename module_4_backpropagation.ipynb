{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "module-4-backpropagation.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNQQBGdSHo/uT00ZBsP753T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/edureka-deep-learning-with-tensorflow/blob/module-4-master-deep-networks/module_4_backpropagation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ERooN3jX2Cn",
        "colab_type": "text"
      },
      "source": [
        "# Backpropagation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ch4I8LbIX2yW",
        "colab_type": "text"
      },
      "source": [
        "Backpropagation is a supervised learning algorithm, for training Multi-layer Perceptrons (Artificial Neural Networks).\n",
        "\n",
        "But, some of you might be wondering why we need to train a Neural Network or what exactly is the meaning of training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8cO264vX9UD",
        "colab_type": "text"
      },
      "source": [
        "## Why We Need Backpropagation?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBwDZpvNX_89",
        "colab_type": "text"
      },
      "source": [
        "While designing a Neural Network, in the beginning, we initialize weights with some random values or any variable for that fact.\n",
        "\n",
        "Now obviously, we are not superhuman. So, it’s not necessary that whatever weight values we have selected will be correct, or it fits our model the best.\n",
        "\n",
        "Okay, fine, we have selected some weight values in the beginning, but our model output is way different than our actual output i.e. the error value is huge.\n",
        "\n",
        "Now, how will you reduce the error?\n",
        "\n",
        "Basically, what we need to do, we need to somehow explain the model to change the parameters (weights), such that error becomes minimum.\n",
        "\n",
        "Let’s put it in an another way, we need to train our model.\n",
        "\n",
        "One way to train our model is called as Backpropagation. Consider the diagram below:\n",
        "\n",
        "<img src='https://d1jnx9ba8s6j9r.cloudfront.net/blog/wp-content/uploads/2017/09/Training-A-Neural-Network-Backpropagation-Edureka-528x216.png?raw=1' width='800'/>\n",
        "\n",
        "Let me summarize the steps for you:\n",
        "\n",
        "* **Calculate the error** – How far is your model output from the actual output.\n",
        "* **Minimum Error** – Check whether the error is minimized or not.\n",
        "* **Update the parameters** – If the error is huge then, update the parameters (weights and biases). After that again check the error. Repeat the process until the error becomes minimum.\n",
        "* **Model is ready to make a prediction** – Once the error becomes minimum, you can feed some inputs to your model and it will produce the output.\n",
        "\n",
        "I am pretty sure, now you know, why we need Backpropagation or why and what is the meaning of training a model.\n",
        "\n",
        "Now is the correct time to understand what is Backpropagation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdS18faBYgGf",
        "colab_type": "text"
      },
      "source": [
        "## What is Backpropagation?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iix-K6R0YjDS",
        "colab_type": "text"
      },
      "source": [
        "The Backpropagation algorithm looks for the minimum value of the error function in weight space using a technique called the delta rule or gradient descent. The weights that minimize the error function is then considered to be a solution to the learning problem. \n",
        "\n",
        "Let’s understand how it works with an example:\n",
        "\n",
        "You have a dataset, which has labels.\n",
        "\n",
        "Consider the below table:\n",
        "\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/bkp-table1.png?raw=1' width='800'/>\n",
        "\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/bkp-table2.png?raw=1' width='800'/>\n",
        "\n",
        "Now, what we did here:\n",
        "\n",
        "* We first initialized some random value to ‘W’ and propagated forward.\n",
        "* Then, we noticed that there is some error. To reduce that error, we propagated backwards and increased the value of ‘W’.\n",
        "* After that, also we noticed that the error has increased. We came to know that, we can’t increase the ‘W’ value. \n",
        "* So, we again propagated backwards and we decreased ‘W’ value.\n",
        "* Now, we noticed that the error has reduced.\n",
        "\n",
        "So, we are trying to get the value of weight such that the error becomes minimum. Basically, we need to figure out whether we need to increase or decrease the weight value. Once we know that, we keep on updating the weight value in that direction until error becomes minimum. You might reach a point, where if you further update the weight, the error will increase. At that time you need to stop, and that is your final weight value.\n",
        "\n",
        "Consider the graph below:\n",
        "\n",
        "<img src='https://d1jnx9ba8s6j9r.cloudfront.net/blog/wp-content/uploads/2017/09/Optimizer-1.png?raw=1' width='800'/>\n",
        "\n",
        "We need to reach the ‘Global Loss Minimum’.\n",
        "\n",
        "This is nothing but Backpropagation.\n",
        "\n",
        "Let’s now understand the math behind Backpropagation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7m-IPWH1ZSZ2",
        "colab_type": "text"
      },
      "source": [
        "## How Backpropagation Works?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cF--nvIZUeb",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}