{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "module-5-assignment-convolutional-neural-networks.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP1C3OPWfIMIuZigmPczOUk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/edureka-deep-learning-with-tensorflow/blob/module-5-convolutional-neural-networks/module_5_assignment_convolutional_neural_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aWtBVdSDrxi",
        "colab_type": "text"
      },
      "source": [
        "# Module 5: Convolutional Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJb45EdPD2vb",
        "colab_type": "text"
      },
      "source": [
        "**Implement convolutional neural-network (CNN) for MNIST Dataset**\n",
        "\n",
        "Network architecture - CNN with 4 layers has following architecture.\n",
        "\n",
        "* Input layer : 784 nodes (MNIST images size)\n",
        "* First convolution layer : 5x5x32\n",
        "* First max-pooling layer\n",
        "* Second convolution layer : 5x5x64\n",
        "* Second max-pooling layer\n",
        "* Third fully-connected layer : 1024 nodes\n",
        "* Output layer : 10 nodes (number of class for MNIST)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4c1Z3GFhEHq1",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-hpxfZ8PKKS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "5acb3cea-276a-4461-cbee-02a006293e93"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras import backend as keras_backend\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.constraints import max_norm\n",
        "from keras.optimizers import Adam, SGD, RMSprop\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "keras_backend.set_image_data_format('channels_last')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q60oZ1-gQnP8",
        "colab_type": "text"
      },
      "source": [
        "## Load and prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZR47opqPQcU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1aa9f90e-6545-494a-cc11-5ec9b5158763"
      },
      "source": [
        "random_seed = 42\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "# load MNIST data and save sizes\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "image_height = X_train.shape[1]\n",
        "image_width = X_train.shape[2]\n",
        "number_of_pixels = image_height * image_width\n",
        "\n",
        "# convert to floating-point\n",
        "X_train = keras_backend.cast_to_floatx(X_train)\n",
        "X_test = keras_backend.cast_to_floatx(X_test)\n",
        "\n",
        "# scale data to range [-1, 1]\n",
        "X_train = np.interp(X_train, [0, 255], [-1,1])\n",
        "X_test = np.interp(X_test, [0, 255], [-1,1])\n",
        "\n",
        "# save original y_train and y_test\n",
        "original_y_train = y_train\n",
        "original_y_test = y_test\n",
        "\n",
        "# replace label data with one-hot encoded versions\n",
        "number_of_classes = 1 + max(np.append(y_train, y_test))\n",
        "y_train = to_categorical(y_train, num_classes=number_of_classes)\n",
        "y_test = to_categorical(y_test, num_classes=number_of_classes)\n",
        "\n",
        "# reshape sample data to 4D tensor using channels_last convention \n",
        "X_train = X_train.reshape(X_train.shape[0], image_height, image_width, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], image_height, image_width, 1)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHK9jAZ-QsWT",
        "colab_type": "text"
      },
      "source": [
        "## Create and train CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5zjyy-UPjqq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the model\n",
        "def make_cnn_model():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (5, 5), activation='relu', padding='same', input_shape=(image_height, image_width, 1)))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Conv2D(64, (5, 5), activation='relu'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1024, activation='relu'))\n",
        "  model.add(Dense(number_of_classes, activation='softmax'))\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIFJp4fiPsRf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "outputId": "a88d3fa3-608d-49e1-b1f2-e4494414a3ef"
      },
      "source": [
        "# create the model and print it structure\n",
        "cnn_model = make_cnn_model()\n",
        "cnn_model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 32)        832       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 10, 10, 64)        51264     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1024)              1639424   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                10250     \n",
            "=================================================================\n",
            "Total params: 1,701,770\n",
            "Trainable params: 1,701,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E93mKECJRYke",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b73c6821-5925-4d60-bee9-43a4c4dc88f4"
      },
      "source": [
        "# train the model\n",
        "cnn_history = cnn_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=256)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "60000/60000 [==============================] - 18s 295us/step - loss: 0.1832 - acc: 0.9464 - val_loss: 0.0480 - val_acc: 0.9844\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.0439 - acc: 0.9864 - val_loss: 0.0343 - val_acc: 0.9886\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.0285 - acc: 0.9908 - val_loss: 0.0275 - val_acc: 0.9905\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.0210 - acc: 0.9935 - val_loss: 0.0235 - val_acc: 0.9915\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 0.0178 - acc: 0.9942 - val_loss: 0.0277 - val_acc: 0.9907\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.0130 - acc: 0.9959 - val_loss: 0.0288 - val_acc: 0.9903\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.0095 - acc: 0.9970 - val_loss: 0.0233 - val_acc: 0.9926\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.0087 - acc: 0.9973 - val_loss: 0.0240 - val_acc: 0.9916\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.0084 - acc: 0.9972 - val_loss: 0.0295 - val_acc: 0.9919\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.0069 - acc: 0.9980 - val_loss: 0.0293 - val_acc: 0.9914\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.0066 - acc: 0.9978 - val_loss: 0.0400 - val_acc: 0.9884\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.0068 - acc: 0.9977 - val_loss: 0.0331 - val_acc: 0.9915\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.0059 - acc: 0.9980 - val_loss: 0.0324 - val_acc: 0.9921\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.0083 - acc: 0.9972 - val_loss: 0.0378 - val_acc: 0.9895\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 0.0050 - acc: 0.9985 - val_loss: 0.0275 - val_acc: 0.9921\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.0031 - acc: 0.9991 - val_loss: 0.0435 - val_acc: 0.9905\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 2s 42us/step - loss: 0.0031 - acc: 0.9990 - val_loss: 0.0317 - val_acc: 0.9929\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 0.0051 - acc: 0.9983 - val_loss: 0.0368 - val_acc: 0.9918\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 0.0042 - acc: 0.9988 - val_loss: 0.0428 - val_acc: 0.9918\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 2s 42us/step - loss: 0.0025 - acc: 0.9993 - val_loss: 0.0424 - val_acc: 0.9910\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 0.0039 - acc: 0.9990 - val_loss: 0.0363 - val_acc: 0.9924\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.0044 - acc: 0.9988 - val_loss: 0.0363 - val_acc: 0.9923\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.0044 - acc: 0.9989 - val_loss: 0.0393 - val_acc: 0.9910\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.0063 - acc: 0.9981 - val_loss: 0.0414 - val_acc: 0.9920\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 0.0030 - acc: 0.9990 - val_loss: 0.0317 - val_acc: 0.9938\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 8.2262e-04 - acc: 0.9999 - val_loss: 0.0350 - val_acc: 0.9931\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 0.0017 - acc: 0.9995 - val_loss: 0.0375 - val_acc: 0.9923\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 0.0026 - acc: 0.9993 - val_loss: 0.0405 - val_acc: 0.9921\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 0.0067 - acc: 0.9980 - val_loss: 0.0504 - val_acc: 0.9888\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.0053 - acc: 0.9984 - val_loss: 0.0406 - val_acc: 0.9937\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.0018 - acc: 0.9994 - val_loss: 0.0393 - val_acc: 0.9930\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.0011 - acc: 0.9998 - val_loss: 0.0380 - val_acc: 0.9936\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 3.8938e-04 - acc: 1.0000 - val_loss: 0.0384 - val_acc: 0.9940\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 2.7783e-04 - acc: 1.0000 - val_loss: 0.0383 - val_acc: 0.9939\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 2.7400e-04 - acc: 1.0000 - val_loss: 0.0384 - val_acc: 0.9939\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 2.7299e-04 - acc: 1.0000 - val_loss: 0.0385 - val_acc: 0.9938\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 2.7230e-04 - acc: 1.0000 - val_loss: 0.0386 - val_acc: 0.9938\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 2.7177e-04 - acc: 1.0000 - val_loss: 0.0387 - val_acc: 0.9938\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 2s 42us/step - loss: 2.7135e-04 - acc: 1.0000 - val_loss: 0.0388 - val_acc: 0.9938\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 2.7101e-04 - acc: 1.0000 - val_loss: 0.0389 - val_acc: 0.9938\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 2.7071e-04 - acc: 1.0000 - val_loss: 0.0390 - val_acc: 0.9938\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 2.7048e-04 - acc: 1.0000 - val_loss: 0.0391 - val_acc: 0.9938\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 2.7026e-04 - acc: 1.0000 - val_loss: 0.0392 - val_acc: 0.9938\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 2.7008e-04 - acc: 1.0000 - val_loss: 0.0393 - val_acc: 0.9938\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 2.6992e-04 - acc: 1.0000 - val_loss: 0.0394 - val_acc: 0.9938\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 2.6979e-04 - acc: 1.0000 - val_loss: 0.0394 - val_acc: 0.9938\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 2.6967e-04 - acc: 1.0000 - val_loss: 0.0395 - val_acc: 0.9938\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 2.6956e-04 - acc: 1.0000 - val_loss: 0.0396 - val_acc: 0.9938\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 2.6947e-04 - acc: 1.0000 - val_loss: 0.0397 - val_acc: 0.9938\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 2.6939e-04 - acc: 1.0000 - val_loss: 0.0398 - val_acc: 0.9938\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 2.6932e-04 - acc: 1.0000 - val_loss: 0.0399 - val_acc: 0.9938\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 2.6925e-04 - acc: 1.0000 - val_loss: 0.0400 - val_acc: 0.9937\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 2.6920e-04 - acc: 1.0000 - val_loss: 0.0401 - val_acc: 0.9937\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 2.6915e-04 - acc: 1.0000 - val_loss: 0.0402 - val_acc: 0.9937\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 2.6910e-04 - acc: 1.0000 - val_loss: 0.0403 - val_acc: 0.9937\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 2s 42us/step - loss: 2.6907e-04 - acc: 1.0000 - val_loss: 0.0404 - val_acc: 0.9937\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 2.6903e-04 - acc: 1.0000 - val_loss: 0.0405 - val_acc: 0.9938\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 2.6900e-04 - acc: 1.0000 - val_loss: 0.0406 - val_acc: 0.9937\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 2.6897e-04 - acc: 1.0000 - val_loss: 0.0407 - val_acc: 0.9937\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 2.6895e-04 - acc: 1.0000 - val_loss: 0.0408 - val_acc: 0.9938\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 2.6893e-04 - acc: 1.0000 - val_loss: 0.0409 - val_acc: 0.9937\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 2s 42us/step - loss: 2.6891e-04 - acc: 1.0000 - val_loss: 0.0410 - val_acc: 0.9939\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 2.6889e-04 - acc: 1.0000 - val_loss: 0.0410 - val_acc: 0.9940\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 2.6887e-04 - acc: 1.0000 - val_loss: 0.0412 - val_acc: 0.9940\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 2.6886e-04 - acc: 1.0000 - val_loss: 0.0413 - val_acc: 0.9940\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 2.6885e-04 - acc: 1.0000 - val_loss: 0.0414 - val_acc: 0.9941\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 2.6884e-04 - acc: 1.0000 - val_loss: 0.0415 - val_acc: 0.9940\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 2.6883e-04 - acc: 1.0000 - val_loss: 0.0416 - val_acc: 0.9941\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 2s 42us/step - loss: 2.6882e-04 - acc: 1.0000 - val_loss: 0.0417 - val_acc: 0.9940\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 2.6881e-04 - acc: 1.0000 - val_loss: 0.0418 - val_acc: 0.9940\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 2.6881e-04 - acc: 1.0000 - val_loss: 0.0419 - val_acc: 0.9940\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 2.6880e-04 - acc: 1.0000 - val_loss: 0.0420 - val_acc: 0.9940\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 2s 42us/step - loss: 2.6879e-04 - acc: 1.0000 - val_loss: 0.0421 - val_acc: 0.9940\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 2.6879e-04 - acc: 1.0000 - val_loss: 0.0422 - val_acc: 0.9940\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 2.6879e-04 - acc: 1.0000 - val_loss: 0.0423 - val_acc: 0.9940\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 2.6878e-04 - acc: 1.0000 - val_loss: 0.0424 - val_acc: 0.9940\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 2.6878e-04 - acc: 1.0000 - val_loss: 0.0425 - val_acc: 0.9939\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 2.6878e-04 - acc: 1.0000 - val_loss: 0.0427 - val_acc: 0.9940\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 2.6877e-04 - acc: 1.0000 - val_loss: 0.0428 - val_acc: 0.9940\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 2.6877e-04 - acc: 1.0000 - val_loss: 0.0429 - val_acc: 0.9939\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 2.6877e-04 - acc: 1.0000 - val_loss: 0.0430 - val_acc: 0.9939\n",
            "Epoch 82/100\n",
            "60000/60000 [==============================] - 2s 42us/step - loss: 2.6877e-04 - acc: 1.0000 - val_loss: 0.0431 - val_acc: 0.9939\n",
            "Epoch 83/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 2.6877e-04 - acc: 1.0000 - val_loss: 0.0432 - val_acc: 0.9940\n",
            "Epoch 84/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 2.6876e-04 - acc: 1.0000 - val_loss: 0.0433 - val_acc: 0.9939\n",
            "Epoch 85/100\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 2.6876e-04 - acc: 1.0000 - val_loss: 0.0434 - val_acc: 0.9940\n",
            "Epoch 86/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 2.6876e-04 - acc: 1.0000 - val_loss: 0.0435 - val_acc: 0.9940\n",
            "Epoch 87/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 2.6876e-04 - acc: 1.0000 - val_loss: 0.0436 - val_acc: 0.9940\n",
            "Epoch 88/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 2.6876e-04 - acc: 1.0000 - val_loss: 0.0437 - val_acc: 0.9940\n",
            "Epoch 89/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 2.6876e-04 - acc: 1.0000 - val_loss: 0.0439 - val_acc: 0.9940\n",
            "Epoch 90/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 2.6876e-04 - acc: 1.0000 - val_loss: 0.0440 - val_acc: 0.9940\n",
            "Epoch 91/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 2.6876e-04 - acc: 1.0000 - val_loss: 0.0441 - val_acc: 0.9940\n",
            "Epoch 92/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 2.6876e-04 - acc: 1.0000 - val_loss: 0.0442 - val_acc: 0.9940\n",
            "Epoch 93/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 2.6876e-04 - acc: 1.0000 - val_loss: 0.0443 - val_acc: 0.9941\n",
            "Epoch 94/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 2.6876e-04 - acc: 1.0000 - val_loss: 0.0444 - val_acc: 0.9942\n",
            "Epoch 95/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 2.6876e-04 - acc: 1.0000 - val_loss: 0.0445 - val_acc: 0.9940\n",
            "Epoch 96/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 2.6876e-04 - acc: 1.0000 - val_loss: 0.0446 - val_acc: 0.9942\n",
            "Epoch 97/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 2.6876e-04 - acc: 1.0000 - val_loss: 0.0447 - val_acc: 0.9942\n",
            "Epoch 98/100\n",
            "60000/60000 [==============================] - 2s 42us/step - loss: 2.6876e-04 - acc: 1.0000 - val_loss: 0.0449 - val_acc: 0.9942\n",
            "Epoch 99/100\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 2.6876e-04 - acc: 1.0000 - val_loss: 0.0450 - val_acc: 0.9942\n",
            "Epoch 100/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 2.6876e-04 - acc: 1.0000 - val_loss: 0.0451 - val_acc: 0.9942\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xS53eaRDPyM5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A little utility to draw accuracy and loss plots\n",
        "def plot_accuracy_and_loss(history, plot_title):\n",
        "    xs = range(len(history.history['acc']))\n",
        "\n",
        "    plt.figure(figsize=(10,3))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(xs, history.history['acc'], label='train')\n",
        "    plt.plot(xs, history.history['val_acc'], label='validation')\n",
        "    plt.legend(loc='lower left')\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.title(plot_title+', Accuracy')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(xs, history.history['loss'], label='train')\n",
        "    plt.plot(xs, history.history['val_loss'], label='validation')\n",
        "    plt.legend(loc='upper left')\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel('loss')\n",
        "    plt.title(plot_title+', Loss')\n",
        "\n",
        "    #plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXwaRg1FP5nL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "0104eb41-c46c-4405-c815-4f6d90958677"
      },
      "source": [
        "# plot the validation accuracy and loss\n",
        "plot_accuracy_and_loss(cnn_history, 'Module 5 Assignment CNN')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAADgCAYAAABGmMFYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x216 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}